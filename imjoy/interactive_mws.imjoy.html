<docs lang = "markdown">
[TODO: write documentation for this plugin.]
</docs>

<config lang = "json">
{
    "name": "MWS Interactive",
    "type": "native-python",
    "version": "0.1.0",
    "description": "[TODO: describe this plugin with one sentence.]",
    "tags": [],
    "ui": "",
    "cover": "",
    "inputs": null,
    "outputs": null,
    "flags": [],
    "icon": "extension",
    "api_version": "0.1.5",
    "env": "conda create -n mws-cpu python=3.7",
    "requirements": ["conda: -c cpape -c conda-forge h5py affogato scikit-image vigra pillow"],
    "dependencies": []
}
</config>


<script lang = "python">
from imjoy import api
import base64
from affogato.segmentation import compute_mws_clustering, MWSGridGraph
from skimage.io import imread, imsave
from PIL import Image
import numpy as np
from time import sleep
# import torch
import io
import asyncio
import concurrent


class ImJoyPlugin():

    def setup(self):
        api.log('initialized')

    def load_image(self, file):
        return imread(file)

    def load_model(self, model_file):
        # TODO: fix this
        return torch.load(model_file)

    def predict(self, model, img):

        # with torch.no_grad():
        #     batch = img[None].astype(np.float32)

        #     # whiten
        #     batch -= batch.mean()
        #     batch /= batch.std()
        #     batch = torch.from_numpy(batch)

        #     affs = model(batch)[0].cpu().numpy()

        # return affs

        # TODO: use the actual model

        import h5py
        with h5py.File("/home/swolf/local/data/hackathon2019/slice0.h5", "r") as h5file:
            prediction = h5file["data"][:]

        return prediction

    def mws_segmentation(self, affs):

        image_shape = affs.shape[1:]
        number_of_nodes = affs.shape[-1] * affs.shape[-2]
        offsets = [[-1, 0],
                   [0, -1],
                   [-3, 0],
                   [0, -3],
                   [-9, 0],
                   [0, -9],
                   [-27, 0],
                   [0, -27]]

        api.log('creating gridgraph')
        graph = MWSGridGraph(image_shape)
        api.log('create local edges')
        uvs, costs = graph.compute_nh_and_weights(1 - affs[:2],
                                                  offsets[:2])

        api.log('create mutex edges')
        mutex_uvs, mutex_costs = graph.compute_nh_and_weights(affs[2:],
                                                              offsets[2:],
                                                              [10, 10],
                                                              True)
        api.log('running mws')
        segmentation = compute_mws_clustering(number_of_nodes,
                                              uvs,
                                              mutex_uvs,
                                              costs,
                                              mutex_costs)

        return segmentation.reshape(image_shape)

    def dummy_run(self, ctx):

        raw_file = "/home/swolf/local/data/hackathon2019/slice0.png"
        model_file = "/home/swolf/local/data/models/isbi_2d.pytorch"

        raw_img = self.load_image(raw_file)
        # model = self.load_model(model_file)
        model = None

        api.log('predicting')
        affinities = self.predict(model, raw_img)
        api.log('running mws')
        segmentation = self.mws_segmentation(affinities)

        api.log('mws done')
        segmentation = (segmentation % 255).astype(np.uint8)

        blend_image = segmentation[:512, :512]
        api.log('uniques' + str(np.unique(blend_image)))
        api.log("blend_shape ", blend_image.shape)
        name_plot = "/home/swolf/pictures/tmp.png"
        imsave(name_plot, blend_image)

        with open(name_plot, 'rb') as f:
            data = f.read()
            api.log("QQQQQQ" + str(type(data)))
            result = base64.b64encode(data).decode('ascii')
            imgurl = 'data:image/png;base64,' + result
            api.createWindow(type='imjoy/image', w=12, h=15, data={"src": imgurl})

    def update_segmentation(self, coords):
        print("working hard")
        img = np.random.randint(0, 255, (500, 400, 3), dtype=np.uint8)
        pimg = Image.fromarray(img)
        pimg.save('blah.png')
        with open('blah.png', 'rb') as f:
            result = base64.b64encode(f.read()).decode('ascii')
        imgurl = 'data:image/png;base64,' + result
        return {'url': imgurl, 'w': 500, 'h': 400}


    async def run(self, ctx):
        print("SEHR VIEL TEXT")
        ann_window = await api.createWindow(type="MWSAnnotator", name="thiswindow", sandbox="allow-same-origin allow-scripts", data={})
        print("show_image ")

        loop = asyncio.get_event_loop()

        seed_name_map = {}
        max_label = 1

        with concurrent.futures.ThreadPoolExecutor() as pool:

            counter = 0
            while True:
                counter += 1
                dirty = await ann_window.is_dirty()
                if dirty:
                    print("found dirty")
                    coords = await ann_window.getAnnotation()

                    # create names for coord objects

                    for c_dict in coords['features']:
                        label = c_dict['properties']['label']
                        if label not in seed_name_map:
                            seed_name_map[label] = max_label
                            max_label += 1

                        c_dict['properties']["name"] = str(seed_name_map[label])

                    print("coords ", coords)

                    result = await loop.run_in_executor(
                        pool, self.update_segmentation, coords)
                    
                    await ann_window.displayimage(result)
                    await ann_window.set_clean()
                await asyncio.sleep(1)

        print('custom thread pool', result)

api.export(ImJoyPlugin())
</script>
